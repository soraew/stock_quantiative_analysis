{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"../../data/\"\n",
    "#stats stuff\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "# ML stuff\n",
    "import numpy as np\n",
    "from numpy.fft import *\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "# DL stuff\n",
    "from torch.autograd import Variable\n",
    "from fastprogress import master_bar, progress_bar\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# basic stuff\n",
    "import datetime\n",
    "import requests\n",
    "import io\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# relative imports\n",
    "from LSTM_preprocess import get_Xy, get_train_test, get_train_df, sliding_windows_mutli_features\n",
    "from hfuncs import check_mkdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### LOAD DATA ######################\n",
    "nasdaq = pd.read_csv(data_root + \"NASDAQ_100_Data_From_2010.csv\", sep=\"\\t\")\n",
    "\n",
    "window_size = 30\n",
    "train_ratio = 0.80\n",
    "device = torch.device('cpu')\n",
    "features = ['Adj_Close', 'log_Volatility', 'log_Volume', 'log_Adj_Close']\n",
    "using = ['FB', 'TSLA', 'AAPL', 'AMZN', 'NVDA', 'MSFT', 'GOOGL']\n",
    "# AAPL(Apple), MSFT(Microsoft), GOOGL(Google), AMZN(Amazon), TSLA(Tesla), FB(Facebook), NVDA(Nvidia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 28\n",
      "x.shape, y.shape (3372, 30, 22) (3372, 7)\n"
     ]
    }
   ],
   "source": [
    "df, features = get_train_df(nasdaq, using, features)\n",
    "x, y = get_Xy(df, window_size)\n",
    "print('x.shape, y.shape',x.shape, y.shape)\n",
    "trainX, trainY, testX, testY = get_train_test(x, y, train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        #self.seq_length = seq_length\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        \n",
    "        # what does the batch_first do\n",
    "        self.lstm = nn.LSTM(\\\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers, \n",
    "            batch_first=True,\n",
    "            dropout = 0.25)\n",
    "        \n",
    "        # Linear(in_features, out_features)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)                                                                                                                                                                                                                           \n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size).to(device))\n",
    "        \n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size).to(device))\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        \n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        \n",
    "        out = self.fc(h_out)                                         \n",
    "        out = self.dropout(out)\n",
    "       \n",
    "        return out\n",
    "\n",
    "# create a nn class (just-for-fun choice :-) \n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Parameters #######\n",
    "num_epochs = 500\n",
    "learning_rate = 1e-3\n",
    "input_size = 22 # features(?)\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "num_classes = 7 # because we are using 7 stocks\n",
    "#########################\n",
    "best_val_loss = 100                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## ONLY RUN FOR TRAINING ######################################\n",
    "### Init Model\n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n",
    "lstm.to(device)\n",
    "\n",
    "### where to save models\n",
    "check_mkdir(\"LSTM_3_out\")\n",
    "\n",
    "### Set Criterion Optimizer and scheduler\n",
    "criterion = torch.nn.MSELoss().to(device) \n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=500, factor=0.5, min_lr=1e-7, eps=1e-08)\n",
    "\n",
    "#optimizer = torch.optim.SGD(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train model\n",
    "for epoch in progress_bar(range(num_epochs)):\n",
    "    lstm.train()\n",
    "    outputs= lstm(trainX.to(device))\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # obtain loss func\n",
    "    loss = criterion(outputs, trainY.to(device))\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    #evaluate on test\n",
    "    lstm.eval()\n",
    "    valid = lstm(testX.to(device))\n",
    "    vall_loss = criterion(valid, testY.to(device))\n",
    "\n",
    "    scheduler.step(vall_loss)\n",
    "\n",
    "    if vall_loss.cpu().item() < best_val_loss:\n",
    "         torch.save(lstm.state_dict(), 'LSTM_3/best_model.pt')\n",
    "         print(\"saved best model epoch:\",epoch,\"val loss is:\",vall_loss.cpu().item())\n",
    "         best_val_loss = vall_loss.cpu().item()\n",
    "\n",
    "    if epoch%50==0:\n",
    "        print(f\"Epoch: {epoch}, loss: {loss.cpu().item()}, valid loss:{vall_loss.cpu().item()}\")\n",
    "\n",
    "\n",
    "# check_mkdir(\"LSTM_3_out\")\n",
    "# torch.save(lstm.state_dict(), 'LSTM_3_out/model1_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pyflux': conda)",
   "name": "python3812jvsc74a57bd0b8bf3bbb95d33652ea8a09e83516ae388afde8f9530fb9552010d87506ab4938"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "b8bf3bbb95d33652ea8a09e83516ae388afde8f9530fb9552010d87506ab4938"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}